from django.core.management.base import BaseCommand
from web.models import CompoundLibrary
from matchms import Spectrum
from matchms.filtering import normalize_intensities

import numpy as np
import pickle
import os
import hnswlib

import gensim
from spec2vec import SpectrumDocument
from spec2vec.vector_operations import calc_vector


MODEL_DIR = "/data2/jiangsiyu/ATNP_Database/model"

SPECTRA_PATH = os.path.join(MODEL_DIR, "standards_spectra.pickle")
INDEX_PATH   = os.path.join(MODEL_DIR, "standards_index.bin")

# âœ… ç›´æ¥å¤ç”¨ä½ å·²æœ‰çš„ GNPS æ­£ç¦»å­æ¨¡å‹
MODEL_PATH  = os.path.join(MODEL_DIR, "Ms2Vec_allGNPSpositive.hdf5")


def parse_peaks_from_json(peaks):
    """
    peaks: JSONField
    [
        {"mz": float, "int": float},
        ...
    ]
    """
    if not isinstance(peaks, list):
        return None, None

    mz, intensities = [], []

    for p in peaks:
        if not isinstance(p, dict):
            continue
        if "mz" not in p or "int" not in p:
            continue
        try:
            mz.append(float(p["mz"]))
            intensities.append(float(p["int"]))
        except Exception:
            continue

    if not mz:
        return None, None

    return np.array(mz, dtype=float), np.array(intensities, dtype=float)


class Command(BaseCommand):
    help = "Build standard MS/MS spectra + Spec2Vec HNSW index"

    def handle(self, *args, **options):

        qs = (
            CompoundLibrary.objects
            .filter(spectrum_type__iexact="standard")
            .filter(peaks__isnull=False)
            .order_by("id")   # âš ï¸ é¡ºåºå¿…é¡»å›ºå®š
        )

        total = qs.count()
        parsed, skipped = 0, 0
        spectra = []

        self.stdout.write(f"Total standard objs = {total}")

        # ======================================================
        # 1ï¸âƒ£ æ„å»º Spectrum åˆ—è¡¨
        # ======================================================
        for obj in qs:
            mz, intensities = parse_peaks_from_json(obj.peaks)
            if mz is None:
                skipped += 1
                continue

            spectrum = Spectrum(
                mz=mz,
                intensities=intensities,
                metadata={
                    "compound_id": obj.id,
                    "ionmode": obj.ionmode,
                    "precursor_mz": obj.precursor_mz or obj.pepmass,
                }
            )

            spectrum = normalize_intensities(spectrum)

            spectra.append(spectrum)
            parsed += 1

        # ======================================================
        # 2ï¸âƒ£ ä¿å­˜ spectra.pickle
        # ======================================================
        with open(SPECTRA_PATH, "wb") as f:
            pickle.dump(spectra, f)

        self.stdout.write(
            self.style.SUCCESS(
                f"Parsed spectra = {parsed}, Skipped = {skipped}"
            )
        )

        # ======================================================
        # 3ï¸âƒ£ è®¡ç®— Spec2Vec å‘é‡ï¼ˆä¸ä½ æ¤ç‰©åº“ä¸€è‡´ï¼‰
        # ======================================================
        self.stdout.write("Loading spec2vec Word2Vec model...")

        w2v_model = gensim.models.Word2Vec.load(MODEL_PATH)
        kv = w2v_model.wv
        dim = kv.vector_size

        vectors = []
        valid_ids = []

        for i, spectrum in enumerate(spectra):
            try:
                doc = SpectrumDocument(spectrum, n_decimals=3)
                vec = calc_vector(
                    w2v_model,   # âš ï¸ model åœ¨å‰
                    doc,
                    allowed_missing_percentage=100
                )
                if vec is None:
                    continue

                vectors.append(vec)
                valid_ids.append(i)

            except Exception:
                continue

            vectors = np.array(vectors, dtype="float32")

            if len(vectors) == 0:
                self.stderr.write("âŒ No valid vectors generated.")
                return

            # ======================================================
            # ğŸ”¥ è¿‡æ»¤ zero / NaN å‘é‡ï¼ˆå¿…é¡»ï¼‰
            # ======================================================
            norms = np.linalg.norm(vectors, axis=1)

            valid_mask = np.isfinite(norms) & (norms > 0)

            vectors = vectors[valid_mask]
            valid_ids = [valid_ids[i] for i in range(len(valid_ids)) if valid_mask[i]]

            if len(vectors) == 0:
                self.stderr.write("âŒ All vectors were zero or NaN after filtering.")
                return

            # ======================================================
            # ğŸ”‘ å•ä½åŒ–ï¼ˆå’Œæ¤ç‰©åº“å®Œå…¨ä¸€è‡´ï¼‰
            # ======================================================
            vectors /= np.linalg.norm(vectors, axis=1, keepdims=True)

            self.stdout.write(
                self.style.SUCCESS(
                    f"Computed vectors after filtering: {vectors.shape}"
                )
            )


        # ======================================================
        # 4ï¸âƒ£ æ„å»º HNSW indexï¼ˆç”Ÿæˆ binï¼‰
        # ======================================================
        index = hnswlib.Index(space="cosine", dim=dim)
        index.init_index(
            max_elements=len(vectors),
            ef_construction=400,
            M=64
        )

        index.add_items(vectors, np.arange(len(vectors)))
        index.set_ef(300)
        index.save_index(INDEX_PATH)

        self.stdout.write(
            self.style.SUCCESS(
                f"âœ… Built standard MS/MS index: {INDEX_PATH}"
            )
        )
